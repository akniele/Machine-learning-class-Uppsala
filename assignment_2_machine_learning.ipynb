{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task\n",
        "This assignment starts out with a working PoS tagger based on LSTMs, an untrained word embedding, and a softmax output over PoS tag. The task is to improve the given model and its evaluation."
      ],
      "metadata": {
        "id": "AkFPJu5KN8Y6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "eiO0ZYOROdx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Our standard imports for maths and basic methodology\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# For user feedback\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Imports for pytorch\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "qDe_KRdlwhSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  for i in range(torch.cuda.device_count()):\n",
        "    print(torch.cuda.get_device_name(i))\n",
        "else:\n",
        "  print(\"No GPU available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1XbrRn0wlK2",
        "outputId": "01b8b7cd-20bf-4955-b56b-4534917bb70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/UniversalDependencies/UD_English-GUM.git\n",
        "!git clone https://github.com/UniversalDependencies/UD_German-GSD.git\n",
        "!git clone https://github.com/UniversalDependencies/UD_Swedish-LinES.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0Mh3J5hysPJ",
        "outputId": "f13b07a0-0751-4ea0-9e5d-ecabd5df7f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'UD_English-GUM' already exists and is not an empty directory.\n",
            "fatal: destination path 'UD_German-GSD' already exists and is not an empty directory.\n",
            "fatal: destination path 'UD_Swedish-LinES' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install conllu\n",
        "\n",
        "import conllu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmR6rsWoywfA",
        "outputId": "5a1cb099-a0d2-41d5-ff57-b39ab29788d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: conllu in /usr/local/lib/python3.7/dist-packages (4.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the extensions part, I decided to implement the GRU model, bidirectionality, and to use both the UD's universal and language-specific tag sets. All three of these are specified as parameters when instantiating an object of the model class. I also added the option of masking some of the tokens in the training data, using weight decay, and dropout."
      ],
      "metadata": {
        "id": "dW6R6-e5nETV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "  def __init__(self,  train_file,  test_file, word_embedding_dim, hidden_dim, lstm=True, bidir=False, universal=True, mask=False, decay=False, drop=False):\n",
        "    super(LSTMTagger, self).__init__()                                          # We need to initialise the class we are inheriting from\n",
        "    self.lstm = lstm                                                            # This simply stores the parameters\n",
        "    self.bidir = bidir\n",
        "    self.universal = universal\n",
        "    self.mask = mask\n",
        "    self.decay = decay\n",
        "    self.drop = drop\n",
        "    self.train_file = train_file \n",
        "    self.test_file = test_file  \n",
        "    self.preprocessing()                                                        # calls parsefile, mask_tokens and pad_and_encode\n",
        "    self.hidden_dim_ = hidden_dim                                     \n",
        "    self.vocabulary_size = len(self.token2idx)\n",
        "    self.tagset_size = len(self.tag2idx)\n",
        "    self._word_embedding = nn.Embedding(num_embeddings=self.vocabulary_size,    # Creates the vector space for the input words\n",
        "                                         embedding_dim=word_embedding_dim, \n",
        "                                         padding_idx=self.token2idx['<PAD>'])\n",
        "    \n",
        "    if self.lstm:\n",
        "      if self.bidir:\n",
        "        self._lstm = nn.LSTM(input_size=word_embedding_dim,                     # The LSTM takes an embedded sentence as input, and outputs \n",
        "                          hidden_size=hidden_dim,                               # vectors with dimensionality lstm_hidden_dim.\n",
        "                          batch_first=True, bidirectional=True)\n",
        "        \n",
        "      else:\n",
        "        self._lstm = nn.LSTM(input_size=word_embedding_dim,                         \n",
        "                          hidden_size=hidden_dim,                           \n",
        "                          batch_first=True, bidirectional=False)\n",
        "\n",
        "    else:\n",
        "      if self.bidir:\n",
        "        self._gru = nn.GRU(input_size=word_embedding_dim,                         \n",
        "                          hidden_size=hidden_dim,                           \n",
        "                          batch_first=True, bidirectional=True)\n",
        "      else:\n",
        "        self._gru = nn.GRU(input_size=word_embedding_dim,                          \n",
        "                          hidden_size=hidden_dim,                           \n",
        "                          batch_first=True, bidirectional=False)\n",
        "    if self.drop:\n",
        "      self.dropout = nn.Dropout(0.25) # dropout\n",
        "      \n",
        "    if bidir:\n",
        "      self._fc = nn.Linear(hidden_dim*2, self.tagset_size)                      # The linear layer maps from the RNN output space to tag space\n",
        "    else:\n",
        "      self._fc = nn.Linear(hidden_dim, self.tagset_size)  \n",
        "    self._softmax = nn.LogSoftmax(dim=1)                                        # Softmax of outputting PDFs over tags\n",
        "    \n",
        "    self.training_loss = list()                                                 # For plotting\n",
        "    self.training_accuracy = list()\n",
        "    self.batch_size = 256 \n",
        "    \n",
        "\n",
        "    if torch.cuda.is_available():                                               # Move the model to the GPU (if we have one)\n",
        "      self.cuda()\n",
        "\n",
        "  def parsefile(self, file_path):                                               # parses the conllu files, outputs X and y\n",
        "    if self.universal:\n",
        "      pos_type = \"upos\"                                                         # upos -> universal pos-tag\n",
        "    else:\n",
        "      pos_type = \"xpos\"                                                         # xpos -> language-specific pos-tag\n",
        "\n",
        "    data = open(file_path, mode=\"r\", encoding=\"utf-8\")\n",
        "    annotations = data.read()\n",
        "    sentences = conllu.parse(annotations)\n",
        "\n",
        "    X = []\n",
        "\n",
        "    for i in range(len(sentences)):\n",
        "      sent_list = []\n",
        "      for element in sentences[i]:\n",
        "        word = element[\"form\"]                                                  # \"form\" refers to the actual word form (as in not the lemma)\n",
        "        sent_list.append(word)\n",
        "      if len(sent_list) > 2:\n",
        "        X.append(sent_list)\n",
        "\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(sentences)):\n",
        "      sent_list = []\n",
        "      for element in sentences[i]:\n",
        "        word = element[pos_type]                                                # choose either universal or lang-specific pos-tag\n",
        "        sent_list.append(word)\n",
        "      if len(sent_list) > 2:\n",
        "        y.append(sent_list)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "  def mask_tokens(self, X):                                                     # masks every 7th token\n",
        "    counter = 100\n",
        "    masking = '<MASK>'\n",
        "    for sentence in X:\n",
        "      for i, word in enumerate(sentence):\n",
        "        if counter == 0:\n",
        "          counter = 100\n",
        "        elif counter % 7 == 0:\n",
        "          sentence[i] = masking\n",
        "        counter -= 1\n",
        "\n",
        "    return X\n",
        "\n",
        "  def token_tag_idx(self, X_train, y_train):                                    # creates token-idx dictionary and tag-idx dictionary\n",
        "    tokens = {token for sentence in X_train for token in sentence}\n",
        "    idx2token = list(tokens)\n",
        "    idx2token.insert(0, '<UNK>')\n",
        "    idx2token.append('<PAD>')\n",
        "    token2idx = {token:idx for idx, token in enumerate(idx2token)}\n",
        "\n",
        "    tags = {tag for tags in y_train for tag in tags}\n",
        "    idx2tag = list(tags)\n",
        "    idx2tag.insert(0, '<UNK>')\n",
        "    idx2tag.append('<PAD>')\n",
        "    tag2idx = {tag:idx for idx, tag in enumerate(idx2tag)}\n",
        "\n",
        "    return token2idx, tag2idx\n",
        "\n",
        "  def pad_and_encode(self, sentences, labels, token2idx, tag2idx):              # padding\n",
        "    assert len(sentences)==len(labels)\n",
        "    assert np.all([len(sentence)==len(tags) for sentence, tags in zip(sentences, labels)])\n",
        "    max_sentence_length = np.max([len(sentence) for sentence in sentences])     # Find out how much to pad\n",
        "    padded_sentences = torch.zeros(len(sentences), max_sentence_length,         # Create data structures with <PAD> as default\n",
        "                                  dtype=torch.long)\n",
        "    padded_sentences[:] = token2idx['<PAD>']\n",
        "    padded_labels = torch.zeros(len(sentences), max_sentence_length, \n",
        "                                dtype=torch.long)\n",
        "    padded_labels[:] = tag2idx['<PAD>']\n",
        "    for i, (sentence, tags) in enumerate(zip(sentences, labels)):               # Loop over the data\n",
        "      for j, token in enumerate(sentence):\n",
        "        if token in token2idx.keys():\n",
        "          padded_sentences[i, j] = token2idx[token]\n",
        "        else:\n",
        "          padded_sentences[i, j] = token2idx['<UNK>']\n",
        "      for j, tag in enumerate(tags):\n",
        "        if tag in tag2idx.keys():\n",
        "          padded_labels[i, j] = tag2idx[tag]\n",
        "        else:\n",
        "          padded_labels[i, j] = tag2idx['<UNK>']                                \n",
        "    return padded_sentences, padded_labels\n",
        "\n",
        "  def batch_iterator(self, sentences, labels):\n",
        "    \"\"\"Helper function for iterating over batches of the data\"\"\"\n",
        "    assert len(sentences) == len(labels)\n",
        "    for i in range(0, len(sentences), self.batch_size):\n",
        "      X, y = self.pad_and_encode(sentences[i:min(i+self.batch_size, len(sentences))], \n",
        "                            labels[i:min(i+self.batch_size, len(sentences))], self.token2idx, self.tag2idx)\n",
        "      if torch.cuda.is_available():                                             # Move data to the GPU, if possible, before yielding it\n",
        "        yield (X.cuda(), y.cuda())\n",
        "      else:\n",
        "        yield (X, y)\n",
        "\n",
        "  def preprocessing(self):\n",
        "    X_train, y_train = self.parsefile(self.train_file)\n",
        "    X_test, y_test = self.parsefile(self.test_file)\n",
        "\n",
        "    if self.mask:\n",
        "      X_train = self.mask_tokens(X_train)\n",
        "\n",
        "    token2idx, tag2idx = self.token_tag_idx(X_train, y_train)\n",
        "    self.token2idx = token2idx\n",
        "    self.tag2idx = tag2idx\n",
        "\n",
        "    ### This piece of the code can be used to calculate a majority baseline ###\n",
        "\n",
        "    #tag_list = [tag for tags in y_train for tag in tags] # create a list with all the tags\n",
        "    #print(\"denominator \", len(tag_list))\n",
        "    #tag_dictionary = dict()\n",
        "    #for tag in tag_list: # create a dictionary with tags as keys and the tags frequency as values\n",
        "    #  if tag in tag_dictionary.keys():\n",
        "    #    tag_dictionary[tag] += 1\n",
        "    #  else:\n",
        "    #    tag_dictionary[tag] = 1\n",
        "\n",
        "    #inverse = [(value, key) for key, value in tag_dictionary.items()]\n",
        "    #print(max(inverse)) # get the key-value pair with the highest value\n",
        "    #print(\"nominator\", tag_dictionary)\n",
        "\n",
        "    X_train_pad, y_train_pad = self.pad_and_encode(X_train, y_train, self.token2idx, self.tag2idx)\n",
        "   \n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    padded_sentences = X_train_pad.to(device)\n",
        "\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "    self.X_test = X_test\n",
        "    self.y_test = y_test\n",
        "\n",
        "\n",
        "  def fitting(self):\n",
        "    loss_function = nn.NLLLoss(ignore_index=self.tag2idx['<PAD>'])              # A loss function that fits our choice of output layer and data. The\n",
        "                                                                                # loss function will ignore the padding index in the targets.\n",
        "    if self.decay:                                                              \n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay=1e-20) # optimizer with or without weight decay\n",
        "    else:\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "                                                                \n",
        "    for epoch in range(5):                                                      # Times to loop over the full dataset\n",
        "      with tqdm(self.batch_iterator(self.X_train, self.y_train), \n",
        "                total=len(self.X_train)//self.batch_size+1, unit=\"batch\", desc=\"Epoch %i\" % epoch) as batches:\n",
        "        for inputs, targets in batches:                                         # Loop once over the training data\n",
        "          self.zero_grad()                                                      # Reset gradients\n",
        "          scores = self(inputs)                                                 # Forward pass\n",
        "          loss = loss_function(scores.view(-1, self.tagset_size),               # Get loss, the data is reshaped as a long line of predictions and targets\n",
        "                              targets.view(-1))   \n",
        "                 \n",
        "          loss.backward()                                                       # Backpropagate the error\n",
        "          optimizer.step()                                                      # Run the optimizer to change the weights w.r.t the loss\n",
        "          predictions = scores.argmax(dim=2, keepdim=True).squeeze()            # Calculate the batch training accuracy\n",
        "          mask = targets!=self.tag2idx['<PAD>']                                 # Create a mask for ignoring <PAD> in the targets\n",
        "          correct = (predictions[mask] == targets[mask]).sum().item()           # Item pulls the value from the GPU automatically (if needed)\n",
        "          accuracy = correct / mask.sum().item()*100\n",
        "          self.training_accuracy.append(accuracy)                               # Save the accuracy for plotting\n",
        "          self.training_loss.append(loss.item())                                # Save the loss for plotting\n",
        "          batches.set_postfix(loss=loss.item(), accuracy=accuracy)\n",
        "          \n",
        "    return self.training_accuracy,self.training_loss                            # Update the progress bar\n",
        "\n",
        "    \n",
        "  def predict(self, train):\n",
        "\n",
        "    if train:\n",
        "      sentences = self.X_train\n",
        "      labels = self.y_train\n",
        "    else:\n",
        "      sentences = self.X_test\n",
        "      labels = self.y_test\n",
        "    with torch.no_grad():                                                       # Do not use the following forward passes to calculate a gradient\n",
        "      n_correct = 0\n",
        "      n_total = 0\n",
        "      for inputs, targets in self.batch_iterator(sentences, labels):            # Loop once over the test data\n",
        "        scores = self(inputs)                                                   # Runs the test data through the model\n",
        "        predictions = scores.argmax(dim=2, keepdim=True).squeeze()              # Finds the predictions\n",
        "        mask = targets!=self.tag2idx['<PAD>']                                   # Create a mask for ignoring <PAD> in the targets\n",
        "        n_correct += (predictions[mask] == targets[mask]).sum().item()          # Sums the number of correct predictions\n",
        "        n_total += mask.sum().item()\n",
        "\n",
        "    return 100*n_correct/n_total\n",
        "  \n",
        "\n",
        "    \n",
        "  def forward(self, padded_sentences):\n",
        "    \"\"\"The forward pass through the network\"\"\"\n",
        "    batch_size, max_sentence_length = padded_sentences.size()\n",
        "\n",
        "    embedded_sentences = self._word_embedding(padded_sentences)                 # Sentences encoded as integers are mapped to vectors    \n",
        "\n",
        "    sentence_lengths = (padded_sentences!=self.token2idx['<PAD>']).sum(dim=1)   # Find the length of sentences\n",
        "    sentence_lengths = sentence_lengths.long().cpu()                            # Ensure the correct format\n",
        "    X = nn.utils.rnn.pack_padded_sequence(embedded_sentences, sentence_lengths, # Pack the embedded data\n",
        "                                          batch_first=True, enforce_sorted=False)\n",
        "    \n",
        "    if self.lstm:\n",
        "      lstm_out, _ = self._lstm(X)                                               # Run the LSTM layer\n",
        "      X, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)       # Unpack the output from the LSTM\n",
        "    else:\n",
        "      gru_out, _ = self._gru(X)\n",
        "      X, _ = nn.utils.rnn.pad_packed_sequence(gru_out, batch_first=True)\n",
        "\n",
        "    \n",
        "\n",
        "    X = X.contiguous().view(-1, X.shape[2])                                     # The output from the LSTM layer is flattened\n",
        "    \n",
        "    if self.drop:                                                               \n",
        "      X = self.dropout(X)                                                       # dropout\n",
        "\n",
        "    tag_space = self._fc(X)                                                     # Fully connected layer\n",
        "    tag_scores = self._softmax(tag_space)                                       # Softmax is applied to normalise the outputs\n",
        "                                      \n",
        "    return tag_scores.view(batch_size, max_sentence_length, self.tagset_size)"
      ],
      "metadata": {
        "id": "JBrQ3t5O3h8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "id": "ywNOWYVxdzej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Originally I was going to use a majority baseline (taking the most common label and checking how often it occurs in the training data (in percent). I tried this for a one-directional LSTM model on English test data with universal tags, and the most common label is Noun. However, since this label only gets about 17% this does not seem like a good baseline, probably because there are too many labels in total (The code for finding the majority baseline can still be found in the model class, for reference).\n",
        "Instead, I have decided to use the original model (the code that was provided), train it with the training data and see what training and test accuracy that results in. These accuracies for English, German and Swedish can be found in the output below."
      ],
      "metadata": {
        "id": "L9_QVAlElCp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run this to get the baselines for English, German and Swedish\n",
        "\n",
        "model_english = LSTMTagger(\"UD_English-GUM/en_gum-ud-train.conllu\", \"UD_English-GUM/en_gum-ud-test.conllu\", \n",
        "                   word_embedding_dim=32, hidden_dim=64)                   \n",
        "   \n",
        "weights = model_english.fitting()                                               # fit the model to the training data                                                    \n",
        "\n",
        "score_english_train = model_english.predict(train=True)                         # predict training accuracy\n",
        "score_english_test = model_english.predict(train=False)                         # predict test accuracy\n",
        "print(\"English baseline training accuracy: \", score_english_train)\n",
        "print(\"English baseline test accuracy: \", score_english_test)\n",
        "\n",
        "\n",
        "model_german = LSTMTagger(\"UD_German-GSD/de_gsd-ud-train.conllu\", \"UD_German-GSD/de_gsd-ud-test.conllu\", \n",
        "                   word_embedding_dim=32, hidden_dim=64)                   \n",
        "   \n",
        "weights = model_german.fitting()                                                # fit the model to the training data         \n",
        "\n",
        "score_german_train = model_german.predict(train=True)                           # predict training accuracy\n",
        "score_german_test = model_german.predict(train=False)                           # predict test accuracy\n",
        "print(\"German baseline training accuracy: \", score_german_train)\n",
        "print(\"German baseline test accuracy: \", score_german_test)\n",
        "\n",
        "model_swedish = LSTMTagger(\"UD_Swedish-LinES/sv_lines-ud-train.conllu\", \"UD_Swedish-LinES/sv_lines-ud-test.conllu\", \n",
        "                   word_embedding_dim=32, hidden_dim=64)\n",
        "\n",
        "weights = model_swedish.fitting()                                               # fit the model to the training data \n",
        "\n",
        "score_swedish_train = model_swedish.predict(train=True)                         # predict training accuracy\n",
        "score_swedish_test = model_swedish.predict(train=False)                         # predict test accuracy\n",
        "print(\"Swedish baseline training accuracy: \", score_swedish_train)\n",
        "print(\"Swedish baseline test accuracy: \", score_swedish_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFGhNZUZh9Ja",
        "outputId": "fe09d5a2-1e2d-417e-99a5-68a6cf689fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 21/21 [00:02<00:00,  7.85batch/s, accuracy=51.4, loss=1.65]\n",
            "Epoch 1: 100%|██████████| 21/21 [00:02<00:00, 10.16batch/s, accuracy=68, loss=1.1]\n",
            "Epoch 2: 100%|██████████| 21/21 [00:02<00:00, 10.29batch/s, accuracy=76.1, loss=0.816]\n",
            "Epoch 3: 100%|██████████| 21/21 [00:02<00:00, 10.16batch/s, accuracy=82, loss=0.614]\n",
            "Epoch 4: 100%|██████████| 21/21 [00:02<00:00, 10.12batch/s, accuracy=86.8, loss=0.45]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English baseline training accuracy:  85.95667002930297\n",
            "English baseline test accuracy:  79.20372983252561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 54/54 [00:05<00:00, 10.45batch/s, accuracy=70.4, loss=0.864]\n",
            "Epoch 1: 100%|██████████| 54/54 [00:05<00:00, 10.61batch/s, accuracy=82.5, loss=0.517]\n",
            "Epoch 2: 100%|██████████| 54/54 [00:05<00:00, 10.49batch/s, accuracy=89.5, loss=0.329]\n",
            "Epoch 3: 100%|██████████| 54/54 [00:05<00:00, 10.50batch/s, accuracy=93, loss=0.221]\n",
            "Epoch 4: 100%|██████████| 54/54 [00:05<00:00, 10.46batch/s, accuracy=95.2, loss=0.159]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "German baseline training accuracy:  95.5489481567593\n",
            "German baseline test accuracy:  84.2425689387609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 13/13 [00:01<00:00, 11.72batch/s, accuracy=42.9, loss=1.93]\n",
            "Epoch 1: 100%|██████████| 13/13 [00:01<00:00, 11.55batch/s, accuracy=60.2, loss=1.32]\n",
            "Epoch 2: 100%|██████████| 13/13 [00:01<00:00, 11.57batch/s, accuracy=69.6, loss=0.963]\n",
            "Epoch 3: 100%|██████████| 13/13 [00:01<00:00, 11.83batch/s, accuracy=77.4, loss=0.717]\n",
            "Epoch 4: 100%|██████████| 13/13 [00:01<00:00, 11.55batch/s, accuracy=83.4, loss=0.534]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Swedish baseline training accuracy:  81.77536362652037\n",
            "Swedish baseline test accuracy:  77.53755522827687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM vs. GRU, bidirectional, universal tags vs. language-specific tags\n",
        "Since German got the highest accuracy for the basic model it is this training and test set that will be used in the following to test performance differences between some different parameter combinations. Parameters are LSTM vs. GRU, bidirectional vs. unidirectional and universal tagset vs. language-specific tagset. The parameter combination that got the highest accuracy score here is  lstm=False,bidir=True, universal=False, i.e. a bidirectional GRU model using language-specific tags. Second best was the bidirectional LSTM model, also using language-specific tags. "
      ],
      "metadata": {
        "id": "hdBVZYv7eW2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_list = []\n",
        "\n",
        "model_german = LSTMTagger(\"UD_German-GSD/de_gsd-ud-train.conllu\", \"UD_German-GSD/de_gsd-ud-test.conllu\", \n",
        "                   word_embedding_dim=32, hidden_dim=64, lstm=True,bidir=False, universal=False)                   \n",
        "weights = model_german.fitting()                                                         \n",
        "score_german_train = model_german.predict(train=True)\n",
        "score_german_test = model_german.predict(train=False)\n",
        "score_list.append(score_german_train)\n",
        "score_list.append(score_german_test)\n",
        "\n",
        "model_german = LSTMTagger(\"UD_German-GSD/de_gsd-ud-train.conllu\", \"UD_German-GSD/de_gsd-ud-test.conllu\", \n",
        "                   word_embedding_dim=32, hidden_dim=64, lstm=False,bidir=False, universal=False)                   \n",
        "weights = model_german.fitting()                                                         \n",
        "score_german_train = model_german.predict(train=True)\n",
        "score_german_test = model_german.predict(train=False)\n",
        "score_list.append(score_german_train)\n",
        "score_list.append(score_german_test)\n",
        "\n",
        "model_german = LSTMTagger(\"UD_German-GSD/de_gsd-ud-train.conllu\", \"UD_German-GSD/de_gsd-ud-test.conllu\", \n",
        "                   word_embedding_dim=32, hidden_dim=64, lstm=True,bidir=True, universal=False)                   \n",
        "weights = model_german.fitting()                                                         \n",
        "score_german_train = model_german.predict(train=True)\n",
        "score_german_test = model_german.predict(train=False)\n",
        "score_list.append(score_german_train)\n",
        "score_list.append(score_german_test)\n",
        "\n",
        "model_german = LSTMTagger(\"UD_German-GSD/de_gsd-ud-train.conllu\", \"UD_German-GSD/de_gsd-ud-test.conllu\", \n",
        "                   word_embedding_dim=32, hidden_dim=64, lstm=False,bidir=True, universal=False)                   \n",
        "weights = model_german.fitting()                                                         \n",
        "score_german_train = model_german.predict(train=True)\n",
        "score_german_test = model_german.predict(train=False)\n",
        "score_list.append(score_german_train)\n",
        "score_list.append(score_german_test)\n",
        "\n",
        "model_german = LSTMTagger(\"UD_German-GSD/de_gsd-ud-train.conllu\", \"UD_German-GSD/de_gsd-ud-test.conllu\", \n",
        "                   word_embedding_dim=32, hidden_dim=64, lstm=True,bidir=True, universal=True)                   \n",
        "weights = model_german.fitting()                                                         \n",
        "score_german_train = model_german.predict(train=True)\n",
        "score_german_test = model_german.predict(train=False)\n",
        "score_list.append(score_german_train)\n",
        "score_list.append(score_german_test)\n",
        "\n",
        "model_german = LSTMTagger(\"UD_German-GSD/de_gsd-ud-train.conllu\", \"UD_German-GSD/de_gsd-ud-test.conllu\", \n",
        "                   word_embedding_dim=32, hidden_dim=64, lstm=False,bidir=False, universal=True)                   \n",
        "weights = model_german.fitting()                                                         \n",
        "score_german_train = model_german.predict(train=True)\n",
        "score_german_test = model_german.predict(train=False)\n",
        "score_list.append(score_german_train)\n",
        "score_list.append(score_german_test)\n",
        "\n",
        "for score in score_list:\n",
        "  print(score)\n",
        "\n",
        "                                               "
      ],
      "metadata": {
        "id": "Mxe6XYCwaIUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e12725-02b1-41be-9cf8-1bb9092cc371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 54/54 [00:05<00:00, 10.25batch/s, accuracy=67.6, loss=1.07]\n",
            "Epoch 1: 100%|██████████| 54/54 [00:05<00:00, 10.35batch/s, accuracy=81.5, loss=0.624]\n",
            "Epoch 2: 100%|██████████| 54/54 [00:05<00:00, 10.27batch/s, accuracy=88.6, loss=0.404]\n",
            "Epoch 3: 100%|██████████| 54/54 [00:05<00:00, 10.27batch/s, accuracy=92.4, loss=0.274]\n",
            "Epoch 4: 100%|██████████| 54/54 [00:05<00:00, 10.26batch/s, accuracy=94.4, loss=0.196]\n",
            "Epoch 0: 100%|██████████| 54/54 [00:05<00:00, 10.45batch/s, accuracy=70.3, loss=0.993]\n",
            "Epoch 1: 100%|██████████| 54/54 [00:05<00:00, 10.52batch/s, accuracy=82.3, loss=0.596]\n",
            "Epoch 2: 100%|██████████| 54/54 [00:05<00:00, 10.40batch/s, accuracy=89.1, loss=0.386]\n",
            "Epoch 3: 100%|██████████| 54/54 [00:05<00:00, 10.54batch/s, accuracy=93, loss=0.255]\n",
            "Epoch 4: 100%|██████████| 54/54 [00:05<00:00, 10.47batch/s, accuracy=95.1, loss=0.176]\n",
            "Epoch 0: 100%|██████████| 54/54 [00:06<00:00,  8.53batch/s, accuracy=73.2, loss=0.858]\n",
            "Epoch 1: 100%|██████████| 54/54 [00:06<00:00,  8.65batch/s, accuracy=85.4, loss=0.476]\n",
            "Epoch 2: 100%|██████████| 54/54 [00:06<00:00,  8.65batch/s, accuracy=91.7, loss=0.284]\n",
            "Epoch 3: 100%|██████████| 54/54 [00:06<00:00,  8.62batch/s, accuracy=95.3, loss=0.17]\n",
            "Epoch 4: 100%|██████████| 54/54 [00:06<00:00,  8.56batch/s, accuracy=97, loss=0.105]\n",
            "Epoch 0: 100%|██████████| 54/54 [00:06<00:00,  8.05batch/s, accuracy=75.6, loss=0.788]\n",
            "Epoch 1: 100%|██████████| 54/54 [00:06<00:00,  8.12batch/s, accuracy=85.8, loss=0.449]\n",
            "Epoch 2: 100%|██████████| 54/54 [00:06<00:00,  8.07batch/s, accuracy=92.2, loss=0.262]\n",
            "Epoch 3: 100%|██████████| 54/54 [00:06<00:00,  8.05batch/s, accuracy=95.7, loss=0.154]\n",
            "Epoch 4: 100%|██████████| 54/54 [00:06<00:00,  8.18batch/s, accuracy=97.6, loss=0.0891]\n",
            "Epoch 0: 100%|██████████| 54/54 [00:06<00:00,  8.69batch/s, accuracy=74.2, loss=0.736]\n",
            "Epoch 1: 100%|██████████| 54/54 [00:06<00:00,  8.77batch/s, accuracy=85.5, loss=0.42]\n",
            "Epoch 2: 100%|██████████| 54/54 [00:06<00:00,  8.77batch/s, accuracy=91.6, loss=0.255]\n",
            "Epoch 3: 100%|██████████| 54/54 [00:06<00:00,  8.76batch/s, accuracy=95.3, loss=0.159]\n",
            "Epoch 4: 100%|██████████| 54/54 [00:06<00:00,  8.79batch/s, accuracy=97.4, loss=0.104]\n",
            "Epoch 0: 100%|██████████| 54/54 [00:05<00:00, 10.67batch/s, accuracy=70.8, loss=0.839]\n",
            "Epoch 1: 100%|██████████| 54/54 [00:04<00:00, 10.84batch/s, accuracy=82.5, loss=0.51]\n",
            "Epoch 2: 100%|██████████| 54/54 [00:04<00:00, 10.81batch/s, accuracy=89.1, loss=0.33]\n",
            "Epoch 3: 100%|██████████| 54/54 [00:05<00:00, 10.73batch/s, accuracy=93.8, loss=0.219]\n",
            "Epoch 4: 100%|██████████| 54/54 [00:04<00:00, 10.84batch/s, accuracy=95.8, loss=0.156]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94.94943849530155\n",
            "84.23063149098722\n",
            "95.52212112405267\n",
            "86.02124865703712\n",
            "97.65934139634705\n",
            "87.31646174047988\n",
            "97.89221494414761\n",
            "89.4532648919661\n",
            "97.34226077366182\n",
            "84.5529425808762\n",
            "95.76430961376525\n",
            "84.49325534200788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changing the hidden_dimensions\n",
        "The default for the hidden dimensions is 64. When raising the hidden dimensions to 84 we get a slightly higher test accuracy, whereas when lowering them to 44, the test accuracy is lower. This could suggest that a higher number of hidden dimensions might be beneficial for the German model. "
      ],
      "metadata": {
        "id": "yr424A5cq3e3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_german = LSTMTagger(\"UD_German-GSD/de_gsd-ud-train.conllu\", \"UD_German-GSD/de_gsd-ud-test.conllu\", \n",
        "                   word_embedding_dim=32, hidden_dim=64)                  \n",
        "\n",
        "weights = model_german.fitting()                                                         \n",
        "\n",
        "score_german_train = model_german.predict(train=True)\n",
        "score_german_test = model_german.predict(train=False)\n",
        "\n",
        "print(f\"Training accuracy German: {score_german_train}\")\n",
        "print(f\"Testing accuracy German: {score_german_test}\")\n",
        "\n",
        "\n",
        "model_german = LSTMTagger(\"UD_German-GSD/de_gsd-ud-train.conllu\", \"UD_German-GSD/de_gsd-ud-test.conllu\", \n",
        "                   word_embedding_dim=32, hidden_dim=84)                   \n",
        "\n",
        "weights = model_german.fitting()                                                         \n",
        "\n",
        "score_german_train = model_german.predict(train=True)\n",
        "score_german_test = model_german.predict(train=False)\n",
        "\n",
        "print(f\"Training accuracy German: {score_german_train}\")\n",
        "print(f\"Testing accuracy German: {score_german_test}\")\n",
        "\n",
        "\n",
        "model_german = LSTMTagger(\"UD_German-GSD/de_gsd-ud-train.conllu\", \"UD_German-GSD/de_gsd-ud-test.conllu\", \n",
        "                   word_embedding_dim=32, hidden_dim=44)                 \n",
        "\n",
        "weights = model_german.fitting()                                                         \n",
        "\n",
        "score_german_train = model_german.predict(train=True)\n",
        "score_german_test = model_german.predict(train=False)\n",
        "\n",
        "print(f\"Training accuracy German: {score_german_train}\")\n",
        "print(f\"Testing accuracy German: {score_german_test}\")"
      ],
      "metadata": {
        "id": "YS0lSDeXqsI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1066c693-8973-4aec-b217-ccdb44686a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 54/54 [00:05<00:00, 10.30batch/s, accuracy=68.4, loss=0.881]\n",
            "Epoch 1: 100%|██████████| 54/54 [00:05<00:00, 10.47batch/s, accuracy=81.9, loss=0.534]\n",
            "Epoch 2: 100%|██████████| 54/54 [00:05<00:00, 10.56batch/s, accuracy=89.3, loss=0.33]\n",
            "Epoch 3: 100%|██████████| 54/54 [00:05<00:00, 10.57batch/s, accuracy=93.8, loss=0.214]\n",
            "Epoch 4: 100%|██████████| 54/54 [00:05<00:00, 10.49batch/s, accuracy=95.5, loss=0.152]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy German: 95.65737408061523\n",
            "Testing accuracy German: 84.81556643189685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 54/54 [00:05<00:00,  9.92batch/s, accuracy=70.6, loss=0.837]\n",
            "Epoch 1: 100%|██████████| 54/54 [00:05<00:00,  9.96batch/s, accuracy=82.7, loss=0.517]\n",
            "Epoch 2: 100%|██████████| 54/54 [00:05<00:00,  9.96batch/s, accuracy=89.6, loss=0.329]\n",
            "Epoch 3: 100%|██████████| 54/54 [00:05<00:00, 10.00batch/s, accuracy=93.6, loss=0.218]\n",
            "Epoch 4: 100%|██████████| 54/54 [00:05<00:00,  9.94batch/s, accuracy=96, loss=0.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy German: 95.93309636121108\n",
            "Testing accuracy German: 85.78846842545065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 54/54 [00:04<00:00, 10.93batch/s, accuracy=67.9, loss=0.95]\n",
            "Epoch 1: 100%|██████████| 54/54 [00:04<00:00, 11.03batch/s, accuracy=81.1, loss=0.555]\n",
            "Epoch 2: 100%|██████████| 54/54 [00:04<00:00, 10.98batch/s, accuracy=88.6, loss=0.36]\n",
            "Epoch 3: 100%|██████████| 54/54 [00:04<00:00, 10.98batch/s, accuracy=92.8, loss=0.246]\n",
            "Epoch 4: 100%|██████████| 54/54 [00:04<00:00, 11.03batch/s, accuracy=95.1, loss=0.176]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy German: 95.21323765025001\n",
            "Testing accuracy German: 80.85233377103975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changing the word embedding dimensions\n",
        "Both when lowering and raising the number of embeddings we get a slightly lower accuracy. This suggests that the number of word embeddings was reasonable for German."
      ],
      "metadata": {
        "id": "ZwSZGRR7q8d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_german = LSTMTagger(\"UD_German-GSD/de_gsd-ud-train.conllu\", \"UD_German-GSD/de_gsd-ud-test.conllu\", \n",
        "                   word_embedding_dim=32, hidden_dim=64)                  \n",
        "\n",
        "weights = model_german.fitting()                                                         \n",
        "\n",
        "score_german_train = model_german.predict(train=True)\n",
        "score_german_test = model_german.predict(train=False)\n",
        "\n",
        "print(f\"Training accuracy German: {score_german_train}\")\n",
        "print(f\"Testing accuracy German: {score_german_test}\")\n",
        "\n",
        "\n",
        "model_german = LSTMTagger(\"UD_German-GSD/de_gsd-ud-train.conllu\", \"UD_German-GSD/de_gsd-ud-test.conllu\", \n",
        "                   word_embedding_dim=22, hidden_dim=64)                   \n",
        "\n",
        "weights = model_german.fitting()                                                         \n",
        "\n",
        "score_german_train = model_german.predict(train=True)\n",
        "score_german_test = model_german.predict(train=False)\n",
        "\n",
        "print(f\"Training accuracy German: {score_german_train}\")\n",
        "print(f\"Testing accuracy German: {score_german_test}\")\n",
        "\n",
        "\n",
        "model_german = LSTMTagger(\"UD_German-GSD/de_gsd-ud-train.conllu\", \"UD_German-GSD/de_gsd-ud-test.conllu\", \n",
        "                   word_embedding_dim=42, hidden_dim=64)                 \n",
        "\n",
        "weights = model_german.fitting()                                                         \n",
        "\n",
        "score_german_train = model_german.predict(train=True)\n",
        "score_german_test = model_german.predict(train=False)\n",
        "\n",
        "print(f\"Training accuracy German: {score_german_train}\")\n",
        "print(f\"Testing accuracy German: {score_german_test}\")"
      ],
      "metadata": {
        "id": "ZZ_ipw4XqsFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9180f3a2-b6ac-4247-9f56-040d832446d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 54/54 [00:05<00:00, 10.51batch/s, accuracy=69.5, loss=0.879]\n",
            "Epoch 1: 100%|██████████| 54/54 [00:05<00:00, 10.50batch/s, accuracy=82, loss=0.528]\n",
            "Epoch 2: 100%|██████████| 54/54 [00:05<00:00, 10.55batch/s, accuracy=89.4, loss=0.328]\n",
            "Epoch 3: 100%|██████████| 54/54 [00:05<00:00, 10.58batch/s, accuracy=93.6, loss=0.214]\n",
            "Epoch 4: 100%|██████████| 54/54 [00:05<00:00, 10.58batch/s, accuracy=95.9, loss=0.147]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy German: 95.81833627685498\n",
            "Testing accuracy German: 85.04237793959652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 54/54 [00:05<00:00, 10.54batch/s, accuracy=65.4, loss=0.999]\n",
            "Epoch 1: 100%|██████████| 54/54 [00:05<00:00, 10.60batch/s, accuracy=79.4, loss=0.603]\n",
            "Epoch 2: 100%|██████████| 54/54 [00:05<00:00, 10.69batch/s, accuracy=87.6, loss=0.385]\n",
            "Epoch 3: 100%|██████████| 54/54 [00:04<00:00, 10.81batch/s, accuracy=92.1, loss=0.257]\n",
            "Epoch 4: 100%|██████████| 54/54 [00:05<00:00, 10.71batch/s, accuracy=94.9, loss=0.181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy German: 94.7396660034428\n",
            "Testing accuracy German: 82.69666945207115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 54/54 [00:05<00:00, 10.47batch/s, accuracy=72, loss=0.817]\n",
            "Epoch 1: 100%|██████████| 54/54 [00:05<00:00, 10.55batch/s, accuracy=83.8, loss=0.482]\n",
            "Epoch 2: 100%|██████████| 54/54 [00:05<00:00, 10.58batch/s, accuracy=90.9, loss=0.294]\n",
            "Epoch 3: 100%|██████████| 54/54 [00:05<00:00, 10.57batch/s, accuracy=94.6, loss=0.193]\n",
            "Epoch 4: 100%|██████████| 54/54 [00:05<00:00, 10.70batch/s, accuracy=96.4, loss=0.135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy German: 96.23042930704284\n",
            "Testing accuracy German: 84.1888504237794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final comments:\n",
        "\n",
        "I did not test all parameter combinations, but all the ones I tested were better than the baseline. Out-of-vocabulary words are handled in the pad_and_encode function."
      ],
      "metadata": {
        "id": "TzBgnD-UOgZ4"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment_2_machine_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eiO0ZYOROdx7",
        "ywNOWYVxdzej",
        "hdBVZYv7eW2q",
        "yr424A5cq3e3",
        "ZwSZGRR7q8d4"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}